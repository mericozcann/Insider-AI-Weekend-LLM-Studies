{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuEcbbIKTkBl",
        "outputId": "7defd378-177e-4fbf-cb48-ff5922da1c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# RhoRisk-Meriç – Full Colab Pipeline (FINAL - CLEAN)\n",
        "# Web-Augmented Financial Risk LLM\n",
        "# ================================\n",
        "\n",
        "# --------- [1] KURULUM ---------\n",
        "!pip install -q transformers accelerate peft bitsandbytes datasets\n",
        "!pip install -q langchain langchain-community faiss-cpu duckduckgo-search sentence-transformers gradio ddgs\n",
        "\n",
        "# Kurulumdan sonra:\n",
        "# Runtime → Restart runtime\n",
        "# Restart sonrası bu hücreyi tekrar çalıştırma.\n",
        "# Direkt [2] numaralı hücreden devam et."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "b5de9fa19a7b42a685c281c8fb8fac22",
            "899718b240a5438ca2373828e15764b7",
            "5f7fd935657846d58c05dc1ef4db9c90",
            "c97ceeb56290421bb0769323a360a3fa",
            "679de311d75a46a49bf0cc0b5b72480c",
            "b4976bd32a154f26bf26cc1d52349b0c",
            "f6d1253851ca4606b4319512eafb3e04"
          ]
        },
        "id": "JLflTUtjUF_J",
        "outputId": "87e6f940-ae86-4d8f-98d3-39c7c10b09da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5de9fa19a7b42a685c281c8fb8fac22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "899718b240a5438ca2373828e15764b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f7fd935657846d58c05dc1ef4db9c90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c97ceeb56290421bb0769323a360a3fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "679de311d75a46a49bf0cc0b5b72480c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4976bd32a154f26bf26cc1d52349b0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6d1253851ca4606b4319512eafb3e04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 12,615,680 || all params: 1,112,664,064 || trainable%: 1.1338\n",
            "✅ RhoRisk-Meriç model + LoRA + 4-bit hazır.\n"
          ]
        }
      ],
      "source": [
        "# --------- [2] MODEL + TOKENIZER + LoRA + 4-BIT (DEPRECATED-FREE) ---------\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "BASE_MODEL_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL_ID,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "\n",
        "SYSTEM_PROMPT = (\n",
        "    \"You are RhoRisk-Meriç, a bilingual Turkish–English AI assistant specialized ONLY in financial risk analytics. \"\n",
        "    \"You answer questions related to credit risk, market risk, liquidity risk, operational risk, model risk, \"\n",
        "    \"systemic risk, Basel regulations, stress testing and financial fraud. \"\n",
        "    \"For non-financial topics you politely redirect to financial risk topics.\"\n",
        ")\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "print(\"✅ RhoRisk-Meriç model + LoRA + 4-bit hazır.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G5ZWH6mJUVqG",
        "outputId": "9f9f6a83-2b7e-4a14-a830-04e7c047a037"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are RhoRisk-Meriç, a bilingual Turkish–English AI assistant specialized ONLY in financial risk analytics. You answer questions related to credit risk, market risk, liquidity risk, operational risk, model risk, systemic risk, Basel regulations, stress testing and financial fraud. For non-financial topics you politely redirect to financial risk topics.\n",
            "\n",
            "User: Finansal risk türlerini kısaca açıkl\n"
          ]
        }
      ],
      "source": [
        "# --------- [3] TEMEL LLM CEVAP FONKSİYONU ---------\n",
        "def llm_answer(prompt, max_new_tokens=256, temperature=0.7, top_p=0.9):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Test:\n",
        "test_prompt = f\"{SYSTEM_PROMPT}\\n\\nUser: Finansal risk türlerini kısaca açıklar mısın?\\nAssistant:\"\n",
        "print(llm_answer(test_prompt)[:400])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "13e004fe40394db19b34774c20de272e",
            "22f56b2974a5410fbfe4b363588e3d43",
            "43f7c5d8a15642b69ac59d5d19868c21",
            "82e94f4827dc41cb82adc3b80f687613",
            "4a2371c9b71445f2afe6baf22ac8959a",
            "bebd1282f2b74a7bbfbc7ce64678f789",
            "3ddb8da437554d808ed83aa8cd273faa",
            "4f64d8c3c78e47949f73aaea7ab12cc2",
            "a33233cbaf9e48eaaff82fc76ffe48b3",
            "89a64617312b47f19f94eda07cf2bab6",
            "a84fde7861154a909672bf594d011c2d"
          ]
        },
        "id": "s5AmFt_7Uhtm",
        "outputId": "d51a72c4-19db-4be9-ec64-351cbd97fa4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1838902463.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13e004fe40394db19b34774c20de272e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22f56b2974a5410fbfe4b363588e3d43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43f7c5d8a15642b69ac59d5d19868c21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82e94f4827dc41cb82adc3b80f687613",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a2371c9b71445f2afe6baf22ac8959a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bebd1282f2b74a7bbfbc7ce64678f789",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ddb8da437554d808ed83aa8cd273faa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f64d8c3c78e47949f73aaea7ab12cc2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a33233cbaf9e48eaaff82fc76ffe48b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89a64617312b47f19f94eda07cf2bab6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a84fde7861154a909672bf594d011c2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LangChain RAG altyapısı hazır.\n"
          ]
        }
      ],
      "source": [
        "# --------- [4] LANGCHAIN + DUCKDUCKGO + FAISS ---------\n",
        "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "search = DuckDuckGoSearchAPIWrapper()\n",
        "embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vector_db = FAISS.from_texts([\"initial\"], embedder)\n",
        "\n",
        "print(\"✅ LangChain RAG altyapısı hazır.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Z3XibmZwUuhA",
        "outputId": "78ffc0d1-3c64-43e3-bb14-798f40241e04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Capital Requirements: Basel III and Its Impact on Capital\n",
            "These are some of the main aspects and implications of Basel iii on capital requirements for financial institutions.\n",
            "https://fastercapital.com/content/Capital-Requirements--Basel-III-and-Its-Impact-on-Capital-Requirements-for-Financial-Instit\n"
          ]
        }
      ],
      "source": [
        "# --------- [5] WEB’DEN BİLGİ ÇEKME ---------\n",
        "def web_retrieve(query, k=3):\n",
        "    results = search.results(query, max_results=5)\n",
        "\n",
        "    texts = []\n",
        "    for r in results:\n",
        "        snippet = r.get(\"snippet\", \"\")\n",
        "        title = r.get(\"title\", \"\")\n",
        "        link = r.get(\"link\", \"\")\n",
        "        combined = f\"{title}\\n{snippet}\\n{link}\"\n",
        "        texts.append(combined)\n",
        "\n",
        "    global vector_db\n",
        "    vector_db.add_texts(texts)\n",
        "    docs = vector_db.similarity_search(query, k=k)\n",
        "    return docs\n",
        "\n",
        "# Test:\n",
        "docs_test = web_retrieve(\"Basel III capital requirements overview\")\n",
        "print(docs_test[0].page_content[:300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "s4QD1qNtUyw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2141d77b-23b6-4c39-cd66-26be7592b815"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yes, Basel III kapsamında piyasa riski için getirilen başlıca yenilikler, birçok farklı yöntemlerden oluşan bir sistem oluşturarak sermaye yeterliliği, likidite yönetimi ve risk kontrol mekanizmalarını güçlendirmek amacıyla uygulanmaya başlanmıştır. Bu kriterler, finansal sistemin istikrarını artırarak olası krizlere karşı dayanıklılığı yükseltmeyi hedefler.\n",
            "\n",
            "[WEB CONTEXT]\n",
            "ISDA, Basel III Ayrışmasının Küresel Piyasalarda Genişlemesiyle Riske ...\n",
            "Paket ISDA, Basel III'ün dengesiz uygulanmasının piyasa likiditesini azaltma ve korunma kapasitesini zayıflatma riski taşıdığını ve bu nedenle riske u\n"
          ]
        }
      ],
      "source": [
        "# --------- [6] RAG + LLM BİRLEŞİMİ ---------\n",
        "def build_rag_prompt(user_question, context_text):\n",
        "    prompt = f\"\"\"\n",
        "{SYSTEM_PROMPT}\n",
        "\n",
        "Below is some external, real-world information retrieved from the web.\n",
        "Use it ONLY as supporting material.\n",
        "\n",
        "[WEB CONTEXT]\n",
        "{context_text}\n",
        "[END OF CONTEXT]\n",
        "\n",
        "User question:\n",
        "{user_question}\n",
        "\n",
        "As RhoRisk-Meriç, provide a clear, professional answer focused on FINANCIAL RISK.\n",
        "Answer in the same language as the question.\n",
        "Assistant:\n",
        "\"\"\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def risk_rag_chat(user_question):\n",
        "    docs = web_retrieve(user_question, k=3)\n",
        "    context = \"\\n\\n---\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "    prompt = build_rag_prompt(user_question, context)\n",
        "    answer_full = llm_answer(prompt, max_new_tokens=320, temperature=0.6, top_p=0.9)\n",
        "\n",
        "    if \"Assistant:\" in answer_full:\n",
        "        answer = answer_full.split(\"Assistant:\")[-1].strip()\n",
        "    else:\n",
        "        answer = answer_full.strip()\n",
        "\n",
        "    return answer\n",
        "\n",
        "# Test:\n",
        "print(risk_rag_chat(\"Basel III kapsamında piyasa riski için getirilen başlıca yenilikler nelerdir?\")[:600])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "P_wjpvjtVKrO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "cb616316-98c2-4ebc-c3c7-540cac5f1ce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c1ea35ecde2c7203e3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c1ea35ecde2c7203e3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# --------- [7] GRADIO CHAT ARAYÜZÜ ---------\n",
        "import gradio as gr\n",
        "\n",
        "def chat_ui(message):\n",
        "    if not message or message.strip() == \"\":\n",
        "        return \"Lütfen finansal risk ile ilgili bir soru yaz.\"\n",
        "    return risk_rag_chat(message)\n",
        "\n",
        "app = gr.Interface(\n",
        "    fn=chat_ui,\n",
        "    inputs=gr.Textbox(label=\"Financial Risk Question\", placeholder=\"Örn: Basel III'e göre likidite riski nasıl ölçülür?\"),\n",
        "    outputs=gr.Textbox(label=\"RhoRisk-Meriç Answer\"),\n",
        "    title=\"RhoRisk-Meriç – Web-Augmented Financial Risk LLM\",\n",
        "    description=\"Ask about credit risk, market risk, Basel, VaR, stress testing, liquidity and fraud.\"\n",
        ")\n",
        "\n",
        "app.launch(share=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}